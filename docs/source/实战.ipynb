{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac9deca-5d33-45d8-982b-ac5425598506",
   "metadata": {},
   "source": [
    "### 坐标轴范围  \n",
    "\n",
    "可以通过`plt.ylim`和`plt.xlim`分别对y轴和x轴的坐标范围进行配置，譬如我们可以设置y轴的起点为50；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35e272-18e6-450c-a0fe-1c15af872251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T15:02:04.756127Z",
     "iopub.status.busy": "2025-01-30T15:02:04.755662Z",
     "iopub.status.idle": "2025-01-30T15:02:04.881383Z",
     "shell.execute_reply": "2025-01-30T15:02:04.880618Z",
     "shell.execute_reply.started": "2025-01-30T15:02:04.756094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.figure(figsize=(8, 6))\n",
    "x = ['1月', '2月', '3月', '4月', '5月', '6月', '7月', '8月', '9月', '10月', '11月', '12月']\n",
    "y1 = [123, 145, 152, 182, 147, 138, 189, 201, 203, 211, 201, 182]\n",
    "y2 = [102, 121, 138, 154, 171, 178, 199, 231, 228, 202, 231, 271]\n",
    "\n",
    "plt.title(\"销售趋势图\", fontdict={'family':'SimHei', 'color': 'k', 'size': 15}, loc='left')\n",
    "plt.plot(x, y1, linestyle='-.', marker='o', markersize=10, color='r', label='华东')  # 绘制图像\n",
    "plt.plot(x, y2, linestyle='-', marker='o', markersize=10, color='y', label='华中')  # 绘制图像\n",
    "plt.xlabel(\"月份\", fontdict={'family':'SimHei', 'color': 'k', 'size': 12}, labelpad=10)\n",
    "plt.ylabel(\"销售额（万元）\", fontdict={'family':'SimHei', 'color': 'k', 'size': 12}, labelpad=10)\n",
    "plt.legend(loc='best', fontsize=12) # best:matplotlib根据图表自动选择最优位置\n",
    "# 设置坐标轴范围\n",
    "plt.ylim(50, 300)\n",
    "# 添加网格线\n",
    "plt.grid(b=True, axis='y', linestyle='--', linewidth=1, color='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2808b-3af6-4005-880a-2841eceaeac3",
   "metadata": {},
   "source": [
    "### 多图  \n",
    "\n",
    "有时候一个图表并不能说明问题，需要通过多子图进行展现；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed539c6e-fe0a-4fe6-87ff-349aaf52249a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T15:10:45.013623Z",
     "iopub.status.busy": "2025-01-30T15:10:45.013027Z",
     "iopub.status.idle": "2025-01-30T15:10:45.120756Z",
     "shell.execute_reply": "2025-01-30T15:10:45.120484Z",
     "shell.execute_reply.started": "2025-01-30T15:10:45.013570Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "\n",
    "x = [\"深圳\", \"广州\", \"北京\", \"上海\"]\n",
    "y = [1, 3, 2, 5]\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.pie(y, labels=x)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.barh(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379cf79-d0fd-4ede-b275-9845ee5169b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 日期处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c0047-240a-4045-9ade-db0487041b95",
   "metadata": {},
   "source": [
    "日期数据在特征工程中通常可以拆分或提取出有用的特征，比如年、月、日、季度、星期等。以下是一些处理日期数据的方法和示例代码："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad26324-d816-4609-9ded-e752bf05b281",
   "metadata": {},
   "source": [
    "1. 提取日期的基本特征\n",
    "    可以从日期中提取以下常见特征：\n",
    "    \n",
    "    年（year）\n",
    "    \n",
    "    月（month）\n",
    "    \n",
    "    日（day）\n",
    "    \n",
    "    星期几（weekday）\n",
    "    \n",
    "    一年中的第几周（weekofyear 或 isocalendar().week）\n",
    "    \n",
    "    一年中的第几天（dayofyear）\n",
    "    \n",
    "    是否为周末（is_weekend）\n",
    "    \n",
    "    示例代码sss\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 示例数据\n",
    "    data = {'date': ['2010-01-01', '2010-05-15', '2010-12-31']}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 将字符串转换为日期类型\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # 提取特征\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['weekday'] = df['date'].dt.weekday  # 0: Monday, 6: Sunday\n",
    "    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)  # 是否为周末\n",
    "    df['quarter'] = df['date'].dt.quarter  # 季度\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear  # 一年中的第几天\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week  # 一年中的第几周\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75f047-e949-4f83-92ff-475a9e5b2432",
   "metadata": {},
   "source": [
    "2. 计算时间差\n",
    "\n",
    "    计算两个日期之间的时间差可以生成新的数值特征，比如某事件过去了多少天、多少月等。\n",
    "    \n",
    "    示例代码\n",
    "    ```python\n",
    "    \n",
    "    # 示例日期\n",
    "    df['reference_date'] = pd.to_datetime('2023-01-01')\n",
    "    \n",
    "    # 计算天数差\n",
    "    df['days_diff'] = (df['reference_date'] - df['date']).dt.days\n",
    "    \n",
    "    # 计算月数差（大致）\n",
    "    df['months_diff'] = (df['reference_date'].dt.year - df['date'].dt.year) * 12 + \\\n",
    "                        (df['reference_date'].dt.month - df['date'].dt.month)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd966f83-db68-4ef4-be0f-9dd8fbab2897",
   "metadata": {},
   "source": [
    "3. 创建周期性特征\n",
    "    一些特征（如月份、星期）有周期性，可以用正弦和余弦变换来捕捉这种关系。\n",
    "    \n",
    "    示例代码\n",
    "\n",
    "   \n",
    "    ```python\n",
    "    import numpy as np\n",
    "    \n",
    "    # 将月份转换为周期特征\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # 将星期几转换为周期特征\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591c4cf-3ff3-4c23-b877-74ca03ab3f43",
   "metadata": {},
   "source": [
    "4. 处理时间段\n",
    "    如果日期代表时间段的开始或结束，可以提取相应的时间间隔特征。例如，计算某天距离最近的假期、季度的开始/结束等。\n",
    "    \n",
    "    ```python\n",
    "    # 判断是否为季度的开始或结束\n",
    "    df['is_quarter_start'] = df['date'].dt.is_quarter_start.astype(int)\n",
    "    df['is_quarter_end'] = df['date'].dt.is_quarter_end.astype(int)\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a505a89-d107-492d-bedb-4f1730be5d97",
   "metadata": {},
   "source": [
    "5. 转换为分类变量\n",
    "    如果某些日期特征的分布对模型有影响，可以将它们离散化为类别变量。例如：\n",
    "    \n",
    "    将年份分组为\"早期\"、\"中期\"、\"近期\"；\n",
    "    将日期划分为工作日和非工作日。\n",
    "    ```python\n",
    "    \n",
    "    # 按年份分组\n",
    "    df['year_group'] = pd.cut(df['year'], bins=[2000, 2010, 2020], labels=['2000s', '2010s'])\n",
    "    \n",
    "    # 将日期划分为工作日/非工作日\n",
    "    df['is_workday'] = (~df['weekday'].isin([5, 6])).astype(int)\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143318d7-4657-44cf-bbfe-f8ab9b82562f",
   "metadata": {},
   "source": [
    "6. 直接使用日期差值\n",
    "    如果日期值表示时间流逝，比如订单时间，可以直接将日期转换为天数或小时数。\n",
    "    \n",
    "    示例代码\n",
    "    ```python\n",
    "    # 将日期转换为时间戳\n",
    "    df['timestamp'] = df['date'].view('int64') // 10**9  # 转为秒\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7ac71-9df8-45da-a36a-5567f7bd90e6",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b0c61-7cb1-4ea5-a1eb-ed25238fd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据\n",
    "data = [['red'], ['blue'], ['green'], ['blue'], ['red']]\n",
    "X = np.array(data)\n",
    "\n",
    "# 创建 OneHotEncoder 对象\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# 拟合并转换数据\n",
    "encoded_data = encoder.fit_transform(X)\n",
    "\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15b070",
   "metadata": {},
   "source": [
    "# Target Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5feea3",
   "metadata": {},
   "source": [
    "基于贝叶斯思想，用先验概率和后验概率的加权平均值作为类别特征值的编码值\n",
    "\n",
    "当特征与label的相关性不明了时，可以尝试Target Encoding来找到signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658ad44f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T14:35:35.548293Z",
     "start_time": "2025-03-01T14:35:35.445555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "Transformed Train Dataset Summary:\n",
      "------------------------------\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        5 non-null      int64  \n",
      " 1   category  5 non-null      float64\n",
      " 2   feature1  5 non-null      int64  \n",
      " 3   feature2  5 non-null      int64  \n",
      " 4   target    5 non-null      int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 328.0 bytes\n",
      "\n",
      "First Rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0.65674</td>\n",
       "      <td>0.514889</td>\n",
       "      <td>0.65674</td>\n",
       "      <td>0.514889</td>\n",
       "      <td>0.652043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          1         2          3          4\n",
       "id         1.00000   2.000000   3.00000   4.000000   5.000000\n",
       "category   0.65674   0.514889   0.65674   0.514889   0.652043\n",
       "feature1  10.00000  20.000000  30.00000  40.000000  50.000000\n",
       "feature2   5.00000  15.000000  25.00000  35.000000  45.000000\n",
       "target     1.00000   0.000000   1.00000   0.000000   1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Test Dataset Summary:\n",
      "------------------------------\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        3 non-null      int64  \n",
      " 1   category  3 non-null      float64\n",
      " 2   feature1  3 non-null      int64  \n",
      " 3   feature2  3 non-null      int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 224.0 bytes\n",
      "\n",
      "First Rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0.514889</td>\n",
       "      <td>0.652043</td>\n",
       "      <td>0.65674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1         2\n",
       "id         6.000000   7.000000   8.00000\n",
       "category   0.514889   0.652043   0.65674\n",
       "feature1  25.000000  35.000000  45.00000\n",
       "feature2  10.000000  20.000000  30.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "# 创建示例训练数据\n",
    "train_data = {\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'category': ['A', 'B', 'A', 'B', 'C'],\n",
    "    'feature1': [10, 20, 30, 40, 50],\n",
    "    'feature2': [5, 15, 25, 35, 45],\n",
    "    'target': [1, 0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'id': [6, 7, 8],\n",
    "    'category': ['B', 'C', 'A'],\n",
    "    'feature1': [25, 35, 45],\n",
    "    'feature2': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# 转换为 DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# 目标列名称\n",
    "label = 'target'\n",
    "\n",
    "# 实例化 TargetEncoder\n",
    "TE = ce.TargetEncoder(smoothing=10)\n",
    "\n",
    "# 获取所有特征列\n",
    "features = test_df.columns.tolist()\n",
    "\n",
    "# 进行目标编码\n",
    "for col in features:\n",
    "    if col not in ['id', label]:  # 忽略 'id' 和 目标列\n",
    "        TE.fit(train_df[col], train_df[label])  # 训练编码器\n",
    "        train_df[col] = TE.transform(train_df[col])  # 转换训练数据\n",
    "        test_df[col] = TE.transform(test_df[col])  # 转换测试数据\n",
    "\n",
    "# 显示数据摘要\n",
    "def display_summary(df, name):\n",
    "    print(f\"\\n{name} Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\nData Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nFirst Rows:\")\n",
    "    display(df.head().T)\n",
    "\n",
    "display_summary(train_df, \"Transformed Train Dataset\")\n",
    "display_summary(test_df, \"Transformed Test Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15687d-a114-445d-a9ca-6d0f3facb2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:25:38.963861Z",
     "iopub.status.busy": "2025-01-08T14:25:38.963308Z",
     "iopub.status.idle": "2025-01-08T14:25:38.970536Z",
     "shell.execute_reply": "2025-01-08T14:25:38.969350Z",
     "shell.execute_reply.started": "2025-01-08T14:25:38.963797Z"
    }
   },
   "source": [
    "# 模型 模版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992488aa-c94d-420e-b2da-3ccfc7101d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:25:52.655067Z",
     "iopub.status.busy": "2025-01-08T14:25:52.654632Z",
     "iopub.status.idle": "2025-01-08T14:25:52.658321Z",
     "shell.execute_reply": "2025-01-08T14:25:52.657564Z",
     "shell.execute_reply.started": "2025-01-08T14:25:52.655021Z"
    }
   },
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7703c8-8e85-4aee-80ae-9ad22bd8cac9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-08T14:26:07.361814Z",
     "iopub.status.busy": "2025-01-08T14:26:07.361368Z",
     "iopub.status.idle": "2025-01-08T14:26:08.272151Z",
     "shell.execute_reply": "2025-01-08T14:26:08.271717Z",
     "shell.execute_reply.started": "2025-01-08T14:26:07.361783Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# XGBoost训练过程\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    " \n",
    "model = xgb.XGBRegressor(max_depth=5, learning_rate=0.5, n_estimators=160, objective='reg:gamma')\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# 对测试集进行预测\n",
    "ans = model.predict(X_test)\n",
    "print(mean_absolute_percentage_error(ans, y_test))\n",
    "# 显示重要特征\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc4007-a923-4516-9b40-49012194e2cf",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df6e93-326d-4c26-80bb-7ce6fd6122a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T12:11:29.093406Z",
     "iopub.status.busy": "2025-01-16T12:11:29.092994Z",
     "iopub.status.idle": "2025-01-16T12:11:30.254393Z",
     "shell.execute_reply": "2025-01-16T12:11:30.254141Z",
     "shell.execute_reply.started": "2025-01-16T12:11:29.093379Z"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 创建示例数据\n",
    "X, y = make_regression(n_samples=10000, n_features=10, noise=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化和训练模型\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabcd1f-14b9-4f0a-adb7-613eaa32de4b",
   "metadata": {},
   "source": [
    "## optuna 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1033f04-a81c-4c0f-9f33-9ae373f590ec",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01715cf1-8b87-48be-a92a-9caa5ef60fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T09:49:17.335890Z",
     "iopub.status.busy": "2024-11-10T09:49:17.335027Z",
     "iopub.status.idle": "2024-11-10T09:49:17.349603Z",
     "shell.execute_reply": "2024-11-10T09:49:17.348402Z",
     "shell.execute_reply.started": "2024-11-10T09:49:17.335826Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 定义 Optuna 目标函数\n",
    "def objective(trial):\n",
    "    # 超参数\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    # K折交叉验证\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    errors = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # 初始化并训练 XGBoost 模型\n",
    "        model = XGBRegressor(**params,early_stopping_rounds=50)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)] , verbose=False)\n",
    "        \n",
    "        # 预测验证集\n",
    "        val_preds = model.predict(X_val)\n",
    "        mse = mean_absolute_percentage_error(y_val, val_preds)\n",
    "        errors.append(mse)\n",
    "    \n",
    "    # 计算 RMSE\n",
    "    mape = np.sqrt(np.mean(errors))\n",
    "    print(mape)\n",
    "    return mape\n",
    "\n",
    "# 使用 Optuna 进行超参数优化\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 输出最佳超参数\n",
    "print(\"Best trial:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b273821-d6bc-4cbb-b600-51dc8b3ca40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T09:50:28.194796Z",
     "iopub.status.busy": "2024-11-10T09:50:28.194117Z",
     "iopub.status.idle": "2024-11-10T09:50:28.737650Z",
     "shell.execute_reply": "2024-11-10T09:50:28.737301Z",
     "shell.execute_reply.started": "2024-11-10T09:50:28.194760Z"
    }
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_contour, plot_param_importances, plot_parallel_coordinate, plot_edf  # 导入Optuna的可视化工具，用于绘制优化历史、参数重要性等\n",
    "#优化历史图\n",
    "fig1 = plot_optimization_history(study_lgbm)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed1617-1e1f-4947-8be2-e9571e4b8842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T13:33:14.925173Z",
     "iopub.status.busy": "2025-01-13T13:33:14.924647Z",
     "iopub.status.idle": "2025-01-13T13:33:14.930266Z",
     "shell.execute_reply": "2025-01-13T13:33:14.929479Z",
     "shell.execute_reply.started": "2025-01-13T13:33:14.925116Z"
    }
   },
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d6716-89f9-445f-87e1-a052c06ffb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "tscv.split(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2dadc-21d3-4b27-b9a2-526366859d73",
   "metadata": {
    "id": "D5552AF3271E4CD4A65AF6E702A81885",
    "jupyter": {},
    "notebookId": "648699bea88689ade9765aaf",
    "runtime": {
     "execution_status": null,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 8. 用 SQL 的方式查询 DataFrame  \n",
    "Pandasql 可以让我们用操作SQL的方式操作一个pandas DataFrame  \n",
    "\n",
    "虽然 DataFrame 有许多 query 方式，但有时候，就是想用 SQL 查😋而且也比较容易展示查询逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f541fbc5-cc62-469c-bff2-bbd65bbcb963",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-01T06:11:32.132429Z",
     "iopub.status.busy": "2025-02-01T06:11:32.131668Z",
     "iopub.status.idle": "2025-02-01T06:11:32.830218Z",
     "shell.execute_reply": "2025-02-01T06:11:32.829779Z",
     "shell.execute_reply.started": "2025-02-01T06:11:32.132357Z"
    },
    "id": "D4BEED255F7B43CBBB3B9667FB0DEADA",
    "jupyter": {
     "outputs_hidden": true
    },
    "notebookId": "648699bea88689ade9765aaf",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092adce0-1641-4891-a55d-fb9372b161fa",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-01T06:11:35.094073Z",
     "iopub.status.busy": "2025-02-01T06:11:35.093587Z",
     "iopub.status.idle": "2025-02-01T06:11:35.379700Z",
     "shell.execute_reply": "2025-02-01T06:11:35.379167Z",
     "shell.execute_reply.started": "2025-02-01T06:11:35.094045Z"
    },
    "id": "8458631B0BD848D1992C77FF6FF50693",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "648699bea88689ade9765aaf",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "#Define a function called SQL\n",
    "def SQL(query):\n",
    "    return(pysqldf(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69382a64-4e03-49d7-a24b-f5a7bc856bc0",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-01T06:11:59.407284Z",
     "iopub.status.busy": "2025-02-01T06:11:59.406595Z",
     "iopub.status.idle": "2025-02-01T06:11:59.423953Z",
     "shell.execute_reply": "2025-02-01T06:11:59.423216Z",
     "shell.execute_reply.started": "2025-02-01T06:11:59.407231Z"
    },
    "id": "5AE4A4A390574BEFA15C81110F5EDE31",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "648699bea88689ade9765aaf",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'apples': [3, 2, 0, 1], 'oranges': [0, 3, 7, 2]}\n",
    "data = pd.DataFrame(data)\n",
    "query = '''\n",
    "    SELECT *\n",
    "    FROM data\n",
    "    WHERE oranges > 0\n",
    "'''\n",
    "\n",
    "SQL(query)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "字符串去重\n",
    "```python ls = set()\n",
    "for l in \"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\"\"\".splitlines():\n",
    "    ls.add(l)\n",
    "```\n"
   ],
   "id": "48e26b1543b0796a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
